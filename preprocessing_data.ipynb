{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from instruments_recognition.importing_data import *\n",
    "from instruments_recognition.signal_processing import *\n",
    "#from instruments_recognition.plotting import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lui/coding/ml/instruments/instruments_recognition/signal_processing.py:420: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 747 samples of viola_philharmonia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IMPORT AND TRANSFORM DATA (this might take a while)\n",
    "\n",
    "    \n",
    "def preprocess_multiwindow_volumes(datadirectory, limit_examples, name) :\n",
    "    wav_files = glob.glob(datadirectory + '*.wav')[:limit_examples]\n",
    "    \n",
    "    multiwindow_volumes = [ signal_to_volumes(FSignal.from_wav_file_and_clean(wav_file)) for wav_file in wav_files ]\n",
    "    print('Preprocessed ' + str(len(wav_files)) + ' samples of ' + name)\n",
    "    \n",
    "    energiesf = open('transformed_data/' + name + '_multiwindow_volumes', 'wb')\n",
    "    np.save(energiesf, multiwindow_volumes)\n",
    "    energiesf.close()\n",
    "\n",
    "\n",
    "instruments = ['viola_philharmonia']\n",
    "#[ preprocess_multiwindow_volumes(ins, limitexamples) for ins in instruments ]\n",
    "#datadirectory = './samples/' + instrument + '/philharmonia/'\n",
    "[ preprocess_multiwindow_volumes('./samples/' + ins + '/' , limitexamples, ins) for ins in instruments ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing signal...\n",
      "Cropping just some seconds...\n",
      "Cropping...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "### CROP AUDIO\n",
    "\n",
    "from instruments_recognition.signal_processing import *\n",
    "#%pylab inline\n",
    "\n",
    "instrument = 'oboe'\n",
    "\n",
    "#datadirectory = './samples/flute/philharmonia/' \n",
    "datadirectory = './samples/long/' + instrument + '/' \n",
    "\n",
    "limit_examples = 10\n",
    "wav_files = glob.glob(datadirectory + '*.wav')[:limit_examples]\n",
    "\n",
    "\n",
    "long_wav = wav_files[0]\n",
    "\n",
    "\n",
    "print('Importing signal...')\n",
    "audio_long = FSignal.from_wav_file_and_clean(long_wav)\n",
    "print('Cropping just some seconds...')\n",
    "audio = audio_long.from_to_sec(120,300)\n",
    "##print('Computing local volume...')\n",
    "##local_volume = audio.local_volume()\n",
    "\n",
    "##print('Finding beats...')\n",
    "##beats = audio.find_beats(20)\n",
    "##beats_beginning = [ b for b,e in beats ]\n",
    "##beats_end = [ e for b,e in beats ]\n",
    "\n",
    "#print('Plotting...')\n",
    "#plt.plot(audio.fsignal)\n",
    "#plt.scatter(beats_beginning, [1 for e in beats_beginning])\n",
    "#plt.show()\n",
    "#\n",
    "#plt.plot(local_volume.fsignal)\n",
    "#plt.scatter(beats_beginning, [20 for e in beats_beginning])\n",
    "#plt.scatter(beats_end, [20 for e in beats_end], color='green')\n",
    "#plt.show()\n",
    "\n",
    "print('Cropping...')\n",
    "cropped_audios = audio.auto_crop(20)\n",
    "\n",
    "savedirectory = './samples/long/cropped/' + instrument + '/'\n",
    "for crop_au in cropped_audios :\n",
    "    #plt.plot(crop_au.fsignal)\n",
    "    #plt.show()\n",
    "    crop_au.to_wav_file(savedirectory)\n",
    "\n",
    "print('Finished')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#OLD\n",
    "def transform_samples_attack_release(instrument,limit_examples,channels):\n",
    "\n",
    "    datadirectory = './samples/' + instrument + '/philharmonia/'\n",
    "    ex_wav = glob.glob(datadirectory + '*.wav')[:limit_examples]\n",
    "\n",
    "    #ex_transformed, freq_label = zip(*map(import_convert_transform, ex_wav))\n",
    "    # zip(ex_transformed, freq_label)\n",
    "\n",
    "    trandlblar, vd = list(zip(*map(lambda e: import_convert_transform2(e,channels), ex_wav)))\n",
    "    \n",
    "    # trandlbla, trandlblr = list(zip(*trandlblar))\n",
    "    energylbl_withmore, tonics = list(zip(* [ harmonics_energy_multiwindow_zipped(ex_tr_freq_lbl) for ex_tr_freq_lbl in trandlblar ]))\n",
    "    energylbla_withmore, energylblr_withmore = list(zip(*energylbl_withmore))\n",
    "    \n",
    "    #energylbla_withmore = [ harmonics_energy_compatiblity(ex_tr, freq_lbl) for ex_tr, freq_lbl in trandlbla ]\n",
    "    #energylblr_withmore = [ harmonics_energy_compatiblity(ex_tr, freq_lbl) for ex_tr, freq_lbl in trandlblr ]\n",
    "\n",
    "    ### Save transformed data to disk\n",
    "    energylblaf = open('transformed_data/' + instrument + '_energylbla_experiment', 'wb')\n",
    "    energylblrf = open('transformed_data/' + instrument + '_energylblr_experiment', 'wb')\n",
    "    \n",
    "    np.save(energylblaf, energylbla_withmore)\n",
    "    np.save(energylblrf, energylblr_withmore)\n",
    "    \n",
    "    #print(energylbl1a_withmore[0])\n",
    "    \n",
    "    energylblaf.close()\n",
    "    energylblrf.close()\n",
    "\n",
    "    \n",
    "\n",
    "#instrument = 'banjo'\n",
    "#limitexamples = 1000\n",
    "#channels = 1\n",
    "#transform_samples_attack_release(instrument,limitexamples,channels)\n",
    "#preprocess_multiwindow_volumes(instrument, limitexamples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
